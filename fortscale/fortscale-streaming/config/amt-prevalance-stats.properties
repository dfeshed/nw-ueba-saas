# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
# ??? extra
job.shutdown.timeout.ms=300000
job.name=amt-prevalence-stats

# Task
task.class=fortscale.streaming.task.EventsPrevalenceModelStreamTask
task.inputs=kafka.fortscale-amt-structured
# Export the state to mongodb every 15 minutes (15 * 60 * 1000 = 900000 ms)
# ??? 14400000
task.window.ms=900000
# task.opts=-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y

# Fortscale specific task config parameters
fortscale.context=classpath*:META-INF/spring/streaming-context.xml
fortscale.source.type=amt
fortscale.entity.type=event
fortscale.timestamp.field=date_time_unix
fortscale.discriminator.fields=yid,action_code,uri,action_string
fortscale.store.name=amt-prevalence-stats
fortscale.models.names.order=amtuser
fortscale.model.amtuser.context.fieldname=normalized_username

fortscale.model.amtuser.fields.date_time_unix.model=fortscale.ml.model.prevalance.field.DailyTimeModel
fortscale.model.amtuser.fields.action_code.model=fortscale.ml.model.prevalance.field.StringCaseInsensitiveValuesCalibrationModel

fortscale.scorers=eventscorer

fortscale.score.eventscorer.output.field.name=EventScore
fortscale.score.eventscorer.scorer=max-scorer
fortscale.score.eventscorer.scorers=dateTimeScorer,actionCodeScorer

fortscale.score.dateTimeScorer.output.field.name=date_time_score
fortscale.score.dateTimeScorer.scorer=model-scorer
fortscale.score.dateTimeScorer.model.name=amtuser
fortscale.score.dateTimeScorer.amtuser.context.fieldname=normalized_username
fortscale.score.dateTimeScorer.amtuser.fieldname=date_time_unix

fortscale.score.actionCodeScorer.output.field.name=action_code_score
fortscale.score.actionCodeScorer.scorer=model-scorer
fortscale.score.actionCodeScorer.model.name=amtuser
fortscale.score.actionCodeScorer.amtuser.context.fieldname=normalized_username
fortscale.score.actionCodeScorer.amtuser.fieldname=action_code
#####
fortscale.fields.action_code.booster=fortscale.streaming.model.prevalance.amt.ActionCodeFieldScoreBooster
fortscale.fields.action_code.whitelist=STARTATT,STARTAMT,VIEWAMT,VIEWAMTDATA,VIEWAVINFO,VIEWFOR,VIEWBT,VIEWATT,VIEWSAMT,VIEWVZ,STARTROGERS,VIEWROGERS,VIEWHSBC,GETCOMMCHANNELERR,CHANGEBDERR,SAMTS1ERR,REACTIVATEERR,DEACTIVATEERR,STOPDELETEERR,DELETEEERR,CORP,EMAILLOOKUP,GUIDLOOKUP
fortscale.fields.action_code.output=action_code_score

fortscale.output.topic=fortscale-amt-event-score
# fortscale.skip.score=false
# fortscale.skip.model=false

### ??? following two lines
fortscale.model.name=amt
fortscale.event.score.field=EventScore

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.jsonmodel.class=fortscale.streaming.serialization.PrevalanceModelSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
metrics.reporter.monitor.class=fortscale.streaming.metrics.MongoMetricsSnapshotReporterFactory
systems.kafka.streams.metrics.samza.msg.serde=metrics
# ??? no monitor
metrics.reporters=snapshot,monitor

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
systems.kafka.producer.retry.backoff.ms=10000
systems.kafka.producer.acks=1
systems.kafka.producer.reconnect.backoff.ms=10000
# ??? missing
# ??? systems.kafka.producer.queue.buffering.max.ms=2000
# Normally we'd set this much higher, but we want things to look snappy in the demo
# ??? 1000
systems.kafka.producer.batch.num.messages=1

# Declare that we want our job's checkpoints to be enabled and written to kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka

# Key-value storage
stores.amt-prevalence-stats.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.amt-prevalence-stats.changelog=kafka.amt-prevalence-stats-changelog
stores.amt-prevalence-stats.key.serde=string
stores.amt-prevalence-stats.msg.serde=jsonmodel
# Normally we'd set this much higher, but we want things to look snappy in the demo
# ??? following 2 lines are extra
stores.amt-prevalence-stats.write.batch.size=0
stores.amt-prevalence-stats.object.cache.size=0

# This property is set to the number of key-value pairs that should be kept in this in-memory buffer, per task instance. The number cannot be greater than stores.*.object.cache.size
stores.amt-prevalence-stats.write.batch.size=50
# This property determines the number of objects to keep in Samza's cache, per task instance. This same cache is also used for write buffering (see stores.*.write.batch.size). A value of 0 disables all caching and batching
stores.amt-prevalence-stats.object.cache.size=500
# The size of LevelDB's block cache in bytes, per container. Note that this is an off-heap memory allocation, so the container's total memory use is the maximum JVM heap size plus the size of this cache
stores.amt-prevalence-stats.container.cache.size.bytes=500000
# The amount of memory (in bytes) that LevelDB uses for buffering writes before they are written to disk
stores.amt-prevalence-stats.container.write.buffer.size.bytes=1000
