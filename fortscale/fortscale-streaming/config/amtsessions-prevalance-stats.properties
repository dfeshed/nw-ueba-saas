# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.shutdown.timeout.ms=300000
job.name=amtsessions-prevalence-stats

# Task
task.class=fortscale.streaming.task.AMTSessionsModelStreamTask
task.inputs=kafka.fortscale-amt-sessionized
# Export the state to mongodb every 4 hours (4 * 60 * 60 * 1000 = 14,400,000 ms)
task.window.ms=14400000
#task.opts=-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y

# Fortscale specific task config parameters
fortscale.context=classpath*:META-INF/spring/streaming-context.xml
fortscale.username.field=username
fortscale.timestamp.field=date_time_unix
fortscale.discriminator.fields=
fortscale.store.name=amtsessions-prevalence-stats
fortscale.model.name=amtsessions

fortscale.source.type=amt
fortscale.entity.type=session
fortscale.timestamp.field=date_time_unix
fortscale.discriminator.fields=
fortscale.store.name=amtsessions-prevalence-stats

fortscale.feature.extractor.normalized_distinct_yid_count.class.name=fortscale.streaming.feature.extractor.EventFeatureExtractor
fortscale.feature.extractor.normalized_distinct_yid_count.class.json={"originalFieldName":"distinct_yid_count","normalizedFieldName":"normalized_distinct_yid_count", "featureAdjustorPriorityList":[{"type":"rate_feature_adjustor","durationAdditionInMin":270,"durationFieldName":"duration"}]}
fortscale.feature.extractor.normalized_sensitive_action_count.class.name=fortscale.streaming.feature.extractor.EventFeatureExtractor
fortscale.feature.extractor.normalized_sensitive_action_count.class.json={"originalFieldName":"sensitive_action_count","normalizedFieldName":"normalized_sensitive_action_count", "featureAdjustorPriorityList":[{"type":"rate_feature_adjustor","durationAdditionInMin":270,"durationFieldName":"duration"}]}
fortscale.feature.extractor.inv_avg_time_in_yid.class.name=fortscale.streaming.feature.extractor.EventFeatureExtractor
fortscale.feature.extractor.inv_avg_time_in_yid.class.json={"originalFieldName":"avg_time_in_yid","featureAdjustorPriorityList":[{"type":"inv_val_feature_adjustor","denominator":0.1}]}
fortscale.feature.extractor.normalized_amt_host.class.name=fortscale.streaming.feature.extractor.EventFeatureExtractor
fortscale.feature.extractor.normalized_amt_host.class.json={"originalFieldName":"avg_time_in_yid","featureAdjustorPriorityList":[{"type":"pattern_replacment_feature_adjustor","pattern":"[0-9]+(?=(.|$))","replacement":""}]}

fortscale.models.names.order=amtsessionsuser,amtsessionshost

fortscale.model.amtsessionsuser.context.fieldname=username
fortscale.model.amtsessionsuser.fields.duration.model=fortscale.streaming.model.prevalance.field.ContinuousValuesFieldModel
fortscale.model.amtsessionsuser.fields.duration.continuous.model.round.number=0.01
fortscale.model.amtsessionsuser.fields.inv_avg_time_in_yid.model=fortscale.streaming.model.prevalance.field.ContinuousValuesFieldModel
fortscale.model.amtsessionsuser.fields.inv_avg_time_in_yid.continuous.model.round.number=0.01
fortscale.model.amtsessionsuser.fields.normalized_distinct_yid_count.model=fortscale.streaming.model.prevalance.field.ContinuousValuesFieldModel
fortscale.model.amtsessionsuser.fields.normalized_distinct_yid_count.continuous.model.round.number=0.01
fortscale.model.amtsessionsuser.fields.normalized_sensitive_action_count.model=fortscale.streaming.model.prevalance.field.ContinuousValuesFieldModel
fortscale.fields.normalized_sensitive_action_count.continuous.model.round.number=0.01
fortscale.model.amtsessionsuser.fields.normalized_amt_host.model=fortscale.streaming.model.prevalance.field.StringCaseInsensitiveValuesCalibrationModel
fortscale.model.amtsessionsuser.fields.start_time_epoch.model=fortscale.streaming.model.prevalance.field.DailyTimeModel

fortscale.model.amtsessionshost.context.fieldname=normalized_amt_host
fortscale.model.amtsessionshost.fields.username.model=fortscale.ml.model.prevalance.field.StringCaseInsensitiveValuesCalibrationModel

fortscale.scorers=eventscorer,startTimeScorer

fortscale.score.eventscorer.output.field.name=EventScore
fortscale.score.eventscorer.scorer=pareto-scorer
fortscale.score.eventscorer.highest.score.weight=0.8
fortscale.score.eventscorer.scorers=

fortscale.score.startTimeScorer.output.field.name=start_time_score
fortscale.score.startTimeScorer.scorer=model-scorer
fortscale.score.startTimeScorer.model.name=amtsessionsuser
fortscale.score.startTimeScorer.amtsessionsuser.context.fieldname=username
fortscale.score.startTimeScorer.amtsessionsuser.fieldname=start_time_epoch

fortscale.score.durationScorer.output.field.name=duration_score
fortscale.score.durationScorer.scorer=cont-model-scorer
fortscale.score.durationScorer.model.name=amtsessionsuser
fortscale.score.durationScorer.vpnsessionuser.context.fieldname=username
fortscale.score.durationScorer.vpnsessionuser.fieldname=duration
fortscale.score.durationScorer.continuous.model.a1=1500
fortscale.score.durationScorer.continuous.model.a2=499999
fortscale.score.durationScorer.continuous.model.largest.p.value=0.001

fortscale.score.invAvgTimeInYidScorer.output.field.name=avg_time_in_yid_score
fortscale.score.invAvgTimeInYidScorer.scorer=low-values-score-reducer
fortscale.score.invAvgTimeInYidScorer.base.scorer=invAvgTimeInYidModelScorer
fortscale.score.invAvgTimeInYidScorer.reduction.configs={"reductionConfigs":[{"reducingValueName":"normalized_distinct_yid_count","reductionFactor":0.1,"maxValueForFullReduction":0.5,"minValueForNoReduction":1.5}]}

fortscale.score.invAvgTimeInYidModelScorer.output.field.name=invAvgTimeInYidModelScore
fortscale.score.invAvgTimeInYidModelScorer.scorer=cont-model-scorer
fortscale.score.invAvgTimeInYidModelScorer.model.name=amtsessionsuser
fortscale.score.invAvgTimeInYidModelScorer.vpnsessionuser.context.fieldname=username
fortscale.score.invAvgTimeInYidModelScorer.vpnsessionuser.fieldname=inv_avg_time_in_yid
fortscale.score.invAvgTimeInYidModelScorer.continuous.model.a1=1500
fortscale.score.invAvgTimeInYidModelScorer.continuous.model.a2=499999
fortscale.score.invAvgTimeInYidModelScorer.continuous.model.largest.p.value=0.001
fortscale.score.invAvgTimeInYidModelScorer.continuous.model.small.value=false

fortscale.score.distinctYidCountScorer.output.field.name=distinct_yid_count_score
fortscale.score.distinctYidCountScorer.scorer=low-values-score-reducer
fortscale.score.distinctYidCountScorer.base.scorer=distinctYidCountModelScorer
fortscale.score.distinctYidCountScorer.reduction.configs={"reductionConfigs":[{"reducingFieldName":"duration","reducingFactor":0.9,"maxValueForFullyReduce":0.5,"minValueForNotReduce":1.5}]}

fortscale.score.distinctYidCountModelScorer.output.field.name=invAvgTimeInYidModelScore
fortscale.score.distinctYidCountModelScorer.scorer=cont-model-scorer
fortscale.score.distinctYidCountModelScorer.model.name=amtsessionsuser
fortscale.score.distinctYidCountModelScorer.vpnsessionuser.context.fieldname=username
fortscale.score.distinctYidCountModelScorer.vpnsessionuser.fieldname=normalized_distinct_yid_count
fortscale.score.distinctYidCountModelScorer.continuous.model.a1=1500
fortscale.score.distinctYidCountModelScorer.continuous.model.a2=499999
fortscale.score.distinctYidCountModelScorer.continuous.model.largest.p.value=0.001
fortscale.score.distinctYidCountModelScorer.continuous.model.small.value=false

fortscale.score.normalizedSensitiveActionCountScorer.output.field.name=sensitive_action_count_score
fortscale.score.normalizedSensitiveActionCountScorer.scorer=low-values-score-reducer
fortscale.score.normalizedSensitiveActionCountScorer.base.scorer=normalizedSensitiveActionCountModelScorer
fortscale.score.normalizedSensitiveActionCountScorer.reduction.configs={"reductionConfigs":[{"reducingFieldName":"duration","reducingFactor":0.9,"maxValueForFullyReduce":0.5,"minValueForNotReduce":1.5},{"reducingFieldName":"sensitive_action_count","reducingFactor":0.25,"maxValueForFullyReduce":1,"minValueForNotReduce":4}]}

fortscale.score.normalizedSensitiveActionCountModelScorer.output.field.name=invAvgTimeInYidModelScore
fortscale.score.normalizedSensitiveActionCountModelScorer.scorer=cont-model-scorer
fortscale.score.normalizedSensitiveActionCountModelScorer.model.name=amtsessionsuser
fortscale.score.normalizedSensitiveActionCountModelScorer.vpnsessionuser.context.fieldname=username
fortscale.score.normalizedSensitiveActionCountModelScorer.vpnsessionuser.fieldname=normalized_sensitive_action_count
fortscale.score.normalizedSensitiveActionCountModelScorer.continuous.model.a1=1500
fortscale.score.normalizedSensitiveActionCountModelScorer.continuous.model.a2=499999
fortscale.score.normalizedSensitiveActionCountModelScorer.continuous.model.largest.p.value=0.001
fortscale.score.normalizedSensitiveActionCountModelScorer.continuous.model.small.value=false

# normalized_amt_host is the hostname with the regular expression replacement defined above (without number)

fortscale.score.hostScorer.output.field.name=amt_host_score
fortscale.score.hostScorer.scorer=reducting-scorer
fortscale.score.hostScorer.main.scorer=hostMainScorer
fortscale.score.hostScorer.reducting.scorer=hostReductingScorer
fortscale.score.hostScorer.reducting.weight=0.5
fortscale.score.hostMainScorer.output.field.name=hostMainScore
fortscale.score.hostMainScorer.scorer=model-scorer
fortscale.score.hostMainScorer.model.name=amtsessionsuser
fortscale.score.hostMainScorer.amtsessionsuser.context.fieldname=username
fortscale.score.hostMainScorer.amtsessionsuser.fieldname=normalized_amt_host
fortscale.score.hostReductingScorer.output.field.name=hostReductingScore
fortscale.score.hostReductingScorer.scorer=model-scorer
fortscale.score.hostReductingScorer.model.name=amtsessionshost
fortscale.score.hostReductingScorer.amtsessionshost.context.fieldname=normalized_amt_host
fortscale.score.hostReductingScorer.amtsessionshost.fieldname=username

# regex pattern and replacement used for normalizing amt_host values
# replacement is empty since we want to clear the numbers from the end of server names
fortscale.host.normalization.pattern=
fortscale.host.normalization.replacement=
fortscale.sourceIp.inCase.EmptyHost=true









fortscale.total.scorer.class.name=fortscale.streaming.scorer.CorrelationCombinedScoresScorer
fortscale.total.scorer.json={"highestScoreWeight":0.8}

fortscale.output.topic=fortscale-amtsessions-event-score
#fortscale.skip.score=false
#fortscale.skip.model=false

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.jsonmodel.class=fortscale.streaming.serialization.PrevalanceModelSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory


# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
metrics.reporter.monitor.class=fortscale.streaming.metrics.MongoMetricsSnapshotReporterFactory
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot,monitor

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
systems.kafka.producer.retry.backoff.ms = 10000
systems.kafka.producer.acks = 1
systems.kafka.producer.reconnect.backoff.ms = 10000
# Normally, we'd set this much higher, but we want things to look snappy in the demo.
systems.kafka.producer.batch.num.messages=1

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka

# Key-value storage
stores.amtsessions-prevalence-stats.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.amtsessions-prevalence-stats.changelog=kafka.amtsessions-prevalence-stats-changelog
stores.amtsessions-prevalence-stats.key.serde=string
stores.amtsessions-prevalence-stats.msg.serde=jsonmodel
# Normally, we'd set this much higher, but we want things to look snappy in the demo.
stores.amtsessions-prevalence-stats.write.batch.size=0
stores.amtsessions-prevalence-stats.object.cache.size=0

# This property is set to the number of key/value pairs that should be kept in this in-memory buffer, per task instance. The number cannot be greater than stores.*.object.cache.size.
stores.amtsessions-prevalence-stats.write.batch.size=50
# This property determines the number of objects to keep in Samza's cache, per task instance. This same cache is also used for write buffering (see stores.*.write.batch.size). A value of 0 disables all caching and batching.
stores.amtsessions-prevalence-stats.object.cache.size=500
# The size of LevelDB's block cache in bytes, per container. Note that this is an off-heap memory allocation, so the container's total memory use is the maximum JVM heap size plus the size of this cache.
stores.amtsessions-prevalence-stats.container.cache.size.bytes=500000
# The amount of memory (in bytes) that LevelDB uses for buffering writes before they are written to disk,
stores.amtsessions-prevalence-stats.container.write.buffer.size.bytes=1000
