# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.shutdown.timeout.ms=300000
job.name=user-score-task

# Task
task.class=fortscale.streaming.task.UserScoreStreamTask
task.inputs=kafka.fortscale-4769-event-score-after-write,kafka.fortscale-ssh-event-score-after-write,kafka.fortscale-vpn-event-score-after-write
# export the state to mongodb every 24 hours
task.window.ms=86400000

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.jsontopevents.class=fortscale.streaming.serialization.GenericJacksonSerdeFactory
serializers.jsontopevents.underlying.class=fortscale.streaming.model.UserTopEvents
serializers.registry.storekeyserde.class=fortscale.streaming.serialization.GenericJacksonSerdeFactory
serializers.storekeyserde.underlying.class=fortscale.streaming.model.UserEventTypePair
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory


# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.bootstrap.servers=localhost:9092
systems.kafka.producer.retry.backoff.ms = 10000
systems.kafka.producer.acks = 1
#systems.kafka.producer.reconnect.backoff.ms = 10000

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka

# Key-value storage
stores.user-score-task-store.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.user-score-task-store.changelog=kafka.user-score-task-store-changelog
stores.user-score-task-store.changelog.replication.factor=1
stores.user-score-task-store.key.serde=storekeyserde
stores.user-score-task-store.msg.serde=jsontopevents
# This property is set to the number of key/value pairs that should be kept in this in-memory buffer, per task instance. The number cannot be greater than stores.*.object.cache.totalFileSystemSize.
stores.user-score-task-store.write.batch.totalFileSystemSize=25
# This property determines the number of objects to keep in Samza's cache, per task instance. This same cache is also usedSpace for write buffering (see stores.*.write.batch.totalFileSystemSize). A value of 0 disables all caching and batching.
stores.user-score-task-store.object.cache.totalFileSystemSize=100
# The totalFileSystemSize of LevelDB's block cache in bytes, per container. Note that this is an off-heap memory allocation, so the container's total memory use is the maximum JVM heap totalFileSystemSize plus the totalFileSystemSize of this cache.
stores.user-score-task-store.container.cache.totalFileSystemSize.bytes=2000
# The amount of memory (in bytes) that LevelDB uses for buffering writes before they are written to disk,
stores.user-score-task-store.container.write.buffer.totalFileSystemSize.bytes=1000


# Fortscale specific task config parameters
fortscale.context=classpath*:META-INF/spring/streaming-user-score-context.xml
fortscale.store.name=user-score-task-store
fortscale.use.latest.event.time.as.current.time=true

# Configuration per data source
#KERBEROS LOGINS
fortscale.data.source.kerberos_logins.classifier=auth
fortscale.data.source.kerberos_logins.username.field=normalized_username
fortscale.data.source.kerberos_logins.timestamp.field=date_time_unix
fortscale.data.source.kerberos_logins.event.score.field=eventscore
fortscale.data.source.kerberos_logins.input.topic=fortscale-4769-event-score-after-write


# SSH:
fortscale.data.source.ssh.classifier=ssh
fortscale.data.source.ssh.username.field=normalized_username
fortscale.data.source.ssh.timestamp.field=date_time_unix
fortscale.data.source.ssh.event.score.field=eventscore
fortscale.data.source.ssh.input.topic=fortscale-ssh-event-score-after-write

# VPN:
fortscale.data.source.vpn.classifier=vpn
fortscale.data.source.vpn.username.field=normalized_username
fortscale.data.source.vpn.timestamp.field=date_time_unix
fortscale.data.source.vpn.event.score.field=eventscore
fortscale.data.source.vpn.input.topic=fortscale-vpn-event-score-after-write

