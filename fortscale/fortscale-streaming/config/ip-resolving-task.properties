# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.name=ip-resolving

# Task

task.class=fortscale.streaming.task.enrichment.IpResolvingStreamTask
task.inputs=kafka.dhcp-resolver-cache,kafka.login-resolver-cache,kafka.fortscale-4769-normalized-tagged-event,kafka.fortscale-4768-normalized-tagged-event,kafka.fortscale-ssh-normalized-tagged-event


# Fortscale specific task config parameters
fortscale.context=classpath*:META-INF/spring/streaming-TaggingTask-context.xml

# map cache logic name into topic and store name
fortscale.dhcp-cache.topic=dhcp-resolver-cache
fortscale.dhcp-cache.store=dhcp-resolver-cache
fortscale.login-cache.topic=login-resolver-cache
fortscale.login-cache.store=login-resolver-cache

# map event input topic into output topics and field names to resolve in each type of event - DUMMY CONFIGS, WILL BE REPLACED NEXT PULL REQUEST
fortscale.events.4769.input.topic=fortscale-4769-normalized-tagged-event
fortscale.events.4769.output.topic=fortscale-4769-ip-resolved
fortscale.events.4769.partition.field=impala.data.security.events.4769.table.morphline.fields.username
fortscale.events.4769.ip.field=impala.data.security.events.4769.table.field.client_address
fortscale.events.4769.host.field=impala.data.security.events.4769.table.field.machine_name
fortscale.events.4769.timestamp.field=impala.data.security.events.4769.table.field.date_time_unix
fortscale.events.4769.restrictToADName=true
fortscale.events.4769.shortName=true
fortscale.events.4769.isRemoveLastDot=false
fortscale.events.4769.dropWhenFail=true

fortscale.events.4768.input.topic=fortscale-4768-normalized-tagged-event
fortscale.events.4768.output.topic=fortscale-4768-ip-resolved
fortscale.events.4768.partition.field=impala.data.security.events.login.table.field.account_name
fortscale.events.4768.ip.field=impala.data.security.events.login.table.field.client_address
fortscale.events.4768.host.field=impala.data.security.events.login.table.field.machine_name
fortscale.events.4768.timestamp.field=impala.data.security.events.login.table.field.date_time_unix
fortscale.events.4768.restrictToADName=true
fortscale.events.4768.shortName=true
fortscale.events.4768.isRemoveLastDot=false
fortscale.events.4768.dropWhenFail=true

fortscale.events.ssh.input.topic=fortscale-ssh-normalized-tagged-event
fortscale.events.ssh.output.topic=fortscale-ssh-ip-resolved

fortscale.events.ssh.partition.field=impala.data.ssh.table.field.username
fortscale.events.ssh.ip.field=impala.data.ssh.table.field.source_ip
fortscale.events.ssh.host.field=impala.data.ssh.table.field.hostname
fortscale.events.ssh.timestamp.field=impala.data.ssh.table.field.epochtime
fortscale.events.ssh.restrictToADName=false
fortscale.events.ssh.shortName=true
fortscale.events.ssh.isRemoveLastDot=false
fortscale.events.ssh.dropWhenFail=false


# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.jsondhcp.class=fortscale.streaming.serialization.DhcpEventSerdeFactory
serializers.registry.jsonlogin.class=fortscale.streaming.serialization.ComputerLoginEventSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.long.class=fortscale.streaming.serialization.LongSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
metrics.reporter.monitor.class=fortscale.streaming.metrics.MongoMetricsSnapshotReporterFactory
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot,monitor


# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.key.serde=string
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=async
systems.kafka.producer.retry.backoff.ms = 10000
systems.kafka.producer.acks = 1
systems.kafka.producer.reconnect.backoff.ms = 10000
systems.kafka.producer.partitioner.class=fortscale.utils.kafka.partitions.StringHashPartitioner
systems.kafka.producer.queue.buffering.max.ms=2000
systems.kafka.producer.batch.num.messages=100

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka

# topic priorities for cache updates should be higher than those for the events topics
systems.kafka.streams.dhcp-resolver-cache.samza.priority=100
systems.kafka.streams.login-resolver-cache.samza.priority=100
systems.kafka.streams.fortscale-4768-normalized-tagged-event.samza.priority=1
systems.kafka.streams.fortscale-4769-normalized-tagged-event.samza.priority=1
systems.kafka.streams.fortscale-ssh-normalized-tagged-event.samza.priority=1


# Key-value storage for dhcp-resolver-cache
stores.dhcp-resolver-cache.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.dhcp-resolver-cache.key.serde=string
stores.dhcp-resolver-cache.msg.serde=jsondhcp
stores.dhcp-resolver-cache.write.batch.size=25
stores.dhcp-resolver-cache.object.cache.size=300000
stores.dhcp-resolver-cache.container.cache.size.bytes=419430400
stores.dhcp-resolver-cache.container.write.buffer.size.bytes=102400


# Key-value storage for logic-resolver-cache
stores.login-resolver-cache.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.login-resolver-cache.key.serde=string
stores.login-resolver-cache.msg.serde=jsonlogin
stores.login-resolver-cache.write.batch.size=25
stores.login-resolver-cache.object.cache.size=300000
stores.login-resolver-cache.container.cache.size.bytes=419430400
stores.login-resolver-cache.container.write.buffer.size.bytes=102400


