# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.name=user-mongo-update-task

# Task
task.class=fortscale.streaming.task.enrichment.UserMongoUpdateTask
task.inputs=kafka.fortscale-vpn-geolocated-session-updated,kafka.fortscale-ssh-normalized-tagged-event,kafka.fortscale-4769-normalized-tagged-event,kafka.fortscale-4768-normalized-tagged-event,kafka.fortscale-amt-geolocated,kafka.fortscale-generic-data-access-normalized-tagged-event,kafka.fortscale-generic-data-access-computer-tagged-clustered


# export the last-activity to mongodb every 15 minutes (15*60*1000=900000ms)
task.window.ms=900000

### Fortscale specific task config parameters
# Spring Context
fortscale.context=classpath*:META-INF/spring/streaming-TaggingTask-context.xml
fortscale.monitoring.enable=true
# Event fields
fortscale.timestamp.field=date_time_unix



## Mapping between topic and data source
#VPN
fortscale.events.entry.name.vpn_UserMongoUpdateStreamTask=vpn_UserMongoUpdateStreamTask
fortscale.events.entry.vpn_UserMongoUpdateStreamTask.data.source=vpn
fortscale.events.entry.vpn_UserMongoUpdateStreamTask.last.state=VpnEnrichTask
fortscale.events.entry.vpn_UserMongoUpdateStreamTask.classifier=vpn
fortscale.events.entry.vpn_UserMongoUpdateStreamTask.success.field=status
fortscale.events.entry.vpn_UserMongoUpdateStreamTask.success.value=SUCCESS
fortscale.events.entry.vpn_UserMongoUpdateStreamTask.updateOnly=false
fortscale.events.entry.vpn_UserMongoUpdateStreamTask.logusername.field=username
fortscale.events.entry.vpn_UserMongoUpdateStreamTask.username.field=normalized_username


#SSH
fortscale.events.entry.name.ssh_UserMongoUpdateStreamTask=ssh_UserMongoUpdateStreamTask
fortscale.events.entry.ssh_UserMongoUpdateStreamTask.data.source=ssh
fortscale.events.entry.ssh_UserMongoUpdateStreamTask.last.state=UsernameNormalizationAndTaggingTask
fortscale.events.entry.ssh_UserMongoUpdateStreamTask.classifier=ssh
fortscale.events.entry.ssh_UserMongoUpdateStreamTask.success.field=status
fortscale.events.entry.ssh_UserMongoUpdateStreamTask.success.value=Accepted
fortscale.events.entry.ssh_UserMongoUpdateStreamTask.updateOnly=true
fortscale.events.entry.ssh_UserMongoUpdateStreamTask.logusername.field=username
fortscale.events.entry.ssh_UserMongoUpdateStreamTask.username.field=normalized_username


#4769
fortscale.events.entry.name.4769_UserMongoUpdateStreamTask=4769_UserMongoUpdateStreamTask
fortscale.events.entry.4769_UserMongoUpdateStreamTask.data.source=kerberos_logins
fortscale.events.entry.4769_UserMongoUpdateStreamTask.last.state=UsernameNormalizationAndTaggingTask
fortscale.events.entry.4769_UserMongoUpdateStreamTask.classifier=auth
fortscale.events.entry.4769_UserMongoUpdateStreamTask.success.field=failure_code
fortscale.events.entry.4769_UserMongoUpdateStreamTask.success.value=0x0
fortscale.events.entry.4769_UserMongoUpdateStreamTask.updateOnly=true
fortscale.events.entry.4769_UserMongoUpdateStreamTask.logusername.field=account_name
fortscale.events.entry.4769_UserMongoUpdateStreamTask.username.field=normalized_username

#4768
fortscale.events.entry.name.4768_UserMongoUpdateStreamTask=4768_UserMongoUpdateStreamTask
fortscale.events.entry.4768_UserMongoUpdateStreamTask.data.source=login4768
fortscale.events.entry.4768_UserMongoUpdateStreamTask.last.state=UsernameNormalizationAndTaggingTask
fortscale.events.entry.4768_UserMongoUpdateStreamTask.classifier=auth
fortscale.events.entry.4768_UserMongoUpdateStreamTask.success.field=status
fortscale.events.entry.4768_UserMongoUpdateStreamTask.success.value=SUCCESS
fortscale.events.entry.4768_UserMongoUpdateStreamTask.updateOnly=true
fortscale.events.entry.4768_UserMongoUpdateStreamTask.logusername.field=account_name
fortscale.events.entry.4768_UserMongoUpdateStreamTask.username.field=normalized_username

#AMT
fortscale.events.entry.name.amt_UserMongoUpdateStreamTask=amt_UserMongoUpdateStreamTask
fortscale.events.entry.amt_UserMongoUpdateStreamTask.data.source=amt
fortscale.events.entry.amt_UserMongoUpdateStreamTask.last.state=VpnEnrichTask
fortscale.events.entry.amt_UserMongoUpdateStreamTask.classifier=amt
fortscale.events.entry.amt_UserMongoUpdateStreamTask.success.field=#AnyRow#
fortscale.events.entry.amt_UserMongoUpdateStreamTask.success.value=#NotRelevant#
fortscale.events.entry.amt_UserMongoUpdateStreamTask.updateOnly=false
fortscale.events.entry.amt_UserMongoUpdateStreamTask.logusername.field=username
fortscale.events.entry.amt_UserMongoUpdateStreamTask.username.field=username

# crmsf
fortscale.events.entry.name.crmsf_UserMongoUpdateStreamTask=crmsf_UserMongoUpdateStreamTask
fortscale.events.entry.crmsf_UserMongoUpdateStreamTask.data.source=crmsf
fortscale.events.entry.crmsf_UserMongoUpdateStreamTask.last.state=VpnEnrichTask
fortscale.events.entry.crmsf_UserMongoUpdateStreamTask.classifier=crmsf
fortscale.events.entry.crmsf_UserMongoUpdateStreamTask.success.field=status
fortscale.events.entry.crmsf_UserMongoUpdateStreamTask.success.value=SUCCESS
fortscale.events.entry.crmsf_UserMongoUpdateStreamTask.logusername.field=username
fortscale.events.entry.crmsf_UserMongoUpdateStreamTask.username.field=normalized_username
fortscale.events.entry.crmsf_UserMongoUpdateStreamTask.updateOnly=false
#############


# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.jsonmodel.class=fortscale.streaming.serialization.UserInfoUpdateSerdFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory


# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot


# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
systems.kafka.producer.retry.backoff.ms = 10000
systems.kafka.producer.acks = 1
systems.kafka.producer.reconnect.backoff.ms = 10000

# Batch side for writing to output topic: Normally, we'd set this much higher, but we want things to look snappy in the demo.
systems.kafka.producer.batch.num.messages=1

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka

# Key-value storage user-last-activity (we're coping it to Mongo from time to time)
stores.user-mongo-update.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.user-mongo-update.changelog=kafka.user-mongo-update-changelog
stores.user-mongo-update.key.serde=string
stores.user-mongo-update.msg.serde=jsonmodel
stores.user-mongo-update.write.batch.size=25
stores.user-mongo-update.object.cache.size=100000
stores.user-mongo-update.container.cache.size.bytes=419430400
stores.user-mongo-update.container.write.buffer.size.bytes=102400
