# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.name=alert-generator-task

# Task
task.class=fortscale.streaming.task.AlertGeneratorTask
task.inputs=kafka.fortscale-evidences

# calling the window function every 15 minutes (15*60*1000=900000ms) (currently not in use)
task.window.ms=900000

### Fortscale specific task config parameters

# Spring Context
fortscale.context=classpath*:META-INF/spring/streaming-AlertGeneratorTask-context.xml

# Event time
fortscale.timestamp.field=date_time_unix

# Threshold for creating alert
fortscale.score.threshold=75

fortscale.events.input.topic=fortscale-evidences
fortscale.events.score.field=score
fortscale.events.normalizedusername.field=normalized_username
# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.jsonmodel.class=fortscale.streaming.serialization.PrevalanceModelSerdeFactory
serializers.registry.long.class=fortscale.streaming.serialization.LongSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory
serializers.registry.timebarrier.class=fortscale.streaming.serialization.UserTimeBarrierModelSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
systems.kafka.producer.retry.backoff.ms = 10000
systems.kafka.producer.acks = 1
systems.kafka.producer.reconnect.backoff.ms = 10000
systems.kafka.producer.queue.buffering.max.ms=2000
systems.kafka.producer.batch.num.messages=1000

#Esper beans and statements

#basic Suspicious hourly activity Alert EPL (evidence count > 3)
#group evidence according to entity type and name, for each specific entity create hourly windows.
#the view assume event are order (but filter out event arriving in delay and are older than the current window time).
#the window is closed once an event newer than the window arrive.
#this statement output the result for each window in a batch, each row contain a different evidence id, but all the other parameters (score, time, entity name and type) are identical for all the records.
fortscale.esper.rule.subscriber.basicSuspiciousHourlyActivity=fortscale.streaming.alert.subscribers.BasicAlertSubscriber
fortscale.esper.rule.statement.basicSuspiciousHourlyActivity=select distinct id,'Suspicious hourly activity' as title,entityType,entityName,min(startDate) as startDate,max(endDate) as endDate,avg(score) as score from SemiOrderEvidenceBach.std:groupwin(entityType,entityName).fortscale:ext_timed_batch(startDate, 1 hour, 0L) group by entityType,entityName having count(*) > 3
fortscale.esper.rule.name.basicSuspiciousHourlyActivity=Hourly Window
