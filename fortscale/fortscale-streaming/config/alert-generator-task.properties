# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.name=alert-generator-task

# Task
task.class=fortscale.streaming.task.AlertGeneratorTask
task.inputs=kafka.fortscale-evidences,kafka.user-tag-service-cache-updates

# calling the window function every 15 minutes (15*60*1000=900000ms) (currently not in use)
task.window.ms=900000

### Fortscale specific task config parameters

# Spring Context
fortscale.context=classpath*:META-INF/spring/streaming-AlertGeneratorTask-context.xml

fortscale.input.info.topic.evidence=fortscale-evidences
fortscale.input.info.class.evidence=fortscale.domain.core.Evidence

fortscale.input.info.topic.user-tags=user-tag-service-cache-updates
fortscale.input.info.convert-method.user-tags=createEntityTags
fortscale.input.info.cache-name.user-tags=entity-tags-cache


# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.jsonmodel.class=fortscale.streaming.serialization.PrevalanceModelSerdeFactory
serializers.registry.long.class=fortscale.streaming.serialization.LongSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory
serializers.registry.timebarrier.class=fortscale.streaming.serialization.UserTimeBarrierModelSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.key.serde=string
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
systems.kafka.producer.retry.backoff.ms = 10000
systems.kafka.producer.acks = 1
systems.kafka.producer.reconnect.backoff.ms = 10000
systems.kafka.producer.queue.buffering.max.ms=2000
systems.kafka.producer.batch.num.messages=1000

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka

#Esper beans and statements
#Suspicious hourly activity Alert EPL (according to Joker Evidence and the existent of tagging)
#Current example uses Evidence since we still don't have a Joker, but will change in the future.
#group Joker evidence according to entity type and name, for each specific entity keep the evidence for 1 sec
#Join it with the tags for which also group according to entity and save the last tag state.
#Current statement will result in creating an Alert for the last Evidence (for each user) also if the tagging was changed to hold the relevant tag - if this is a problem can be changed to
#fortscale.esper.rule.name.JokerAndTagging=Suspicious Session Activity with tagging
#fortscale.esper.rule.statement.JokerAndTagging=select distinct id,'Suspicious hourly activity with Admin' as title,Evidence.entityType as entityType,Evidence.entityName as entityName,startDate,endDate,score*1.0 as score from Evidence(score > 85).std:groupwin(entityType,entityName).win:time(1 sec) as Evidence left outer join EntityTags.std:groupwin(entityType,entityName).std:lastevent() as Tags on Evidence.entityType = Tags.entityType and Evidence.entityName = Tags.entityName where Evidence.score > 95 or (Evidence.score > 85 and 'admin' = any(Tags.tags))
#fortscale.esper.rule.auto-create.JokerAndTagging=true
#fortscale.esper.rule.subscriberBean.JokerAndTagging=basicSubscriber



#basic Suspicious hourly activity Alert EPL (evidence count > 3)
#group evidence according to entity type and name, for each specific entity create hourly windows.
#the view assume event are order (but filter out event arriving in delay and are older than the current window time).
#the window is closed once an event newer than the window arrive.
#this statement output the result for each window in a batch, each row contain a different evidence id, but all the other parameters (score, time, entity name and type) are identical for all the records.
fortscale.esper.rule.name.basicSuspiciousHourlyActivity=Hourly Window
fortscale.esper.rule.statement.basicSuspiciousHourlyActivity=select distinct id,'Suspicious hourly activity' as title,entityType,entityName,min(startDate) as startDate,max(endDate) as endDate,avg(score) as score from SemiOrderEvidenceBach.std:groupwin(entityType,entityName).fortscale:ext_timed_batch(startDate, 1 hour, 0L) group by entityType,entityName having count(*) > 3
fortscale.esper.rule.auto-create.basicSuspiciousHourlyActivity=true
fortscale.esper.rule.subscriberBean.basicSuspiciousHourlyActivity=basicSubscriber


# semi ordering preparation step for incoming evidence.
# the ordering is preform in batches of 10 min and is output to a new stream called SemiOrderEvidenceBach - for the use of any other EPL
# the assumption that the collector will work in a manner where all event from all data sources for a given entity and time range will arrive to the streaming in a max delay of 10 min.
fortscale.esper.rule.name.semiOrdering=Semi Ordering in batches
fortscale.esper.rule.statement.semiOrdering=insert into SemiOrderEvidenceBach select * from Evidence.win:time_batch(10 min) order by startDate
fortscale.esper.rule.auto-create.semiOrdering=true
fortscale.esper.rule.subscriberBean.semiOrdering=none



# Key-value storage for user-tag-cache
stores.entity-tags-cache.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.entity-tags-cache.changelog=kafka.entity-tags-cache-changelog
stores.entity-tags-cache.key.serde=string
stores.entity-tags-cache.msg.serde=json
stores.entity-tags-cache.write.batch.size=25
stores.entity-tags-cache.object.cache.size=200000
stores.entity-tags-cache.container.cache.size.bytes=52428800
stores.entity-tags-cache.container.write.buffer.size.bytes=102400