# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.name=alert-generator-task

# Task
task.class=fortscale.streaming.task.AlertGeneratorTask
task.inputs=kafka.fortscale-evidences,kafka.user-tag-service-cache-updates

# calling the window function every 15 minutes (15*60*1000=900000ms) (currently not in use)
task.window.ms=900000

### Fortscale specific task config parameters

# Spring Context
fortscale.context=classpath*:META-INF/spring/streaming-AlertGeneratorTask-context.xml

fortscale.input.info.topic.evidence=fortscale-evidences
fortscale.input.info.class.evidence=fortscale.domain.core.Evidence

fortscale.input.info.topic.user-tags=user-tag-service-cache-updates
fortscale.input.info.convert-method.user-tags=createEntityTags
fortscale.input.info.cache-name.user-tags=entity-tags-cache


# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.jsonmodel.class=fortscale.streaming.serialization.PrevalanceModelSerdeFactory
serializers.registry.long.class=fortscale.streaming.serialization.LongSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory
serializers.registry.timebarrier.class=fortscale.streaming.serialization.UserTimeBarrierModelSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.key.serde=string
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
systems.kafka.producer.retry.backoff.ms = 10000
systems.kafka.producer.acks = 1
systems.kafka.producer.reconnect.backoff.ms = 10000
systems.kafka.producer.queue.buffering.max.ms=2000
systems.kafka.producer.batch.num.messages=1000

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka

#Esper beans and statements
#Suspicious hourly activity Alert EPL (according to Joker Evidence and the existent of tagging)
#Current example uses Evidence since we still don't have a Joker, but will change in the future.
#group Joker evidence according to entity type and name, for each specific entity keep the evidence for 1 sec
#Join it with the tags for which also group according to entity and save the last tag state.
#Current statement will result in creating an Alert for the last Evidence (for each user) also if the tagging was changed to hold the relevant tag - if this is a problem can be changed to
#fortscale.esper.rule.name.JokerAndTagging=Suspicious Session Activity with tagging
#fortscale.esper.rule.statement.JokerAndTagging=select distinct id,'Suspicious hourly activity with Admin' as title,Evidence.entityType as entityType,Evidence.entityName as entityName,startDate,endDate,score*1.0 as score from Evidence(score > 85).std:groupwin(entityType,entityName).win:time(1 sec) as Evidence left outer join EntityTags.std:groupwin(entityType,entityName).std:lastevent() as Tags on Evidence.entityType = Tags.entityType and Evidence.entityName = Tags.entityName where Evidence.score > 95 or (Evidence.score > 85 and 'admin' = any(Tags.tags))
#fortscale.esper.rule.auto-create.JokerAndTagging=true
#fortscale.esper.rule.subscriberBean.JokerAndTagging=basicSubscriber


# compute for each Evidence the related hourly,daily frame
# when new time period will be needed in the future, need to add them first in here
fortscale.esper.rule.name._1enrichedEvidence=Enriched evidence with time frames
fortscale.esper.rule.statement._1enrichedEvidence=insert into EnrichedEvidence select id, entityType,entityName, startDate, endDate, score, Math.round(startDate/3600000) as hourlyStartDate, Math.round(startDate/86400000) as dailyStartDate from Evidence
fortscale.esper.rule.auto-create._1enrichedEvidence=true
fortscale.esper.rule.subscriberBean._1enrichedEvidence=none


#group evidence according to entity type and name and hourly time period
#over this aggregation there is a check of inactivity for an hour, to make sure we got all th data related to that combination of entity and time frame.
#in order for this statement to output the result in a batch there is a use of the rstream, each row contain a different evidence id, but all the other parameters (score, time, entity name and type) are identical for all the records.
fortscale.esper.rule.name._2accumulateHourActivity=Hourly Window accumulate
fortscale.esper.rule.statement._2accumulateHourActivity=insert rstream into HourlyEnrichedEvidence select * from EnrichedEvidence.std:groupwin(entityType,entityName,hourlyStartDate).win:time_accum(1 hour)
fortscale.esper.rule.auto-create._2accumulateHourActivity=true
fortscale.esper.rule.subscriberBean._2accumulateHourActivity=none


#basic Suspicious hourly activity Alert EPL (evidence count > 3)
fortscale.esper.rule.name._3suspiciousHourByCount=Suspicious Hourly Window
fortscale.esper.rule.statement._3suspiciousHourByCount=select distinct window(id) idList ,hourlyStartDate,'Suspicious hourly activity' as title,entityType,entityName,min(startDate) as startDate,max(endDate) as endDate,avg(score) as score from HourlyEnrichedEvidence.std:groupwin(entityType,entityName,hourlyStartDate).win:time_batch(10 sec) group by entityType,entityName,hourlyStartDate having count(*) > 3
fortscale.esper.rule.auto-create._3suspiciousHourByCount=true
fortscale.esper.rule.subscriberBean._3suspiciousHourByCount=basicSubscriber


# Key-value storage for user-tag-cache
stores.entity-tags-cache.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.entity-tags-cache.changelog=kafka.entity-tags-cache-changelog
stores.entity-tags-cache.key.serde=string
stores.entity-tags-cache.msg.serde=json
stores.entity-tags-cache.write.batch.size=25
stores.entity-tags-cache.object.cache.size=200000
stores.entity-tags-cache.container.cache.size.bytes=52428800
stores.entity-tags-cache.container.write.buffer.size.bytes=102400