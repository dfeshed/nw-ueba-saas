# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.shutdown.timeout.ms=300000
job.name=amt-sessionize

# Task
task.class=fortscale.streaming.task.AMTSessionizeStreamTask
task.inputs=kafka.fortscale-amt-geolocated
# Check for closed sessions every 30 minutes (30 * 60 * 1000 = 1800000 ms)
task.window.ms=1800000
# task.opts=-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y

# Fortscale specific task config parameters
fortscale.context=classpath*:META-INF/spring/streaming-TaggingTask-context.xml
fortscale.session.store.name=sessionize-amt
fortscale.output.topic=fortscale-amt-sessionized
# Consider a session closed if it has been more than 4.5 hours since the last activity (4.5 * 60 * 60 * 1000 = 16,200,000 ms)
fortscale.session.numOfMillisecondsForClosingSession=16200000
# Consider a maximum time for a session as 24 hours
fortscale.session.maxSessionDuration=24
# Consider a YID as a new case if it hasn't been touched for 2 hours
fortscale.session.staleYidSessionTimeoutMillis=7200000
# Exclude sessions that do not contain YIDs
fortscale.session.excludeEmpty=true
# Exclude sessions that the only events in them are matching the following regexp
fortscale.session.excludeSessionWithOnlyEvent.regexp=^(START).*$
# List of sensitive action codes to count in a session (values should be in upper case)
fortscale.session.sensitive.action.codes=LOGINASMAIL,UNAUTHACCESS,LOGINAS,WSLOGINAS,LOGINASATT,LOGINASROGERS,CORP,CHANGEPW
# List of sensitive action codes to notify in case of sensitive YID
fortscale.session.sensitive.notification.action.codes=VIEWAVINFO,VIEWFOR,VIEWPWQ
# regexp (substring of action code) for notification
fortscale.session.sensitive.notification.action.code.regexp=^(LOGINAS).*$
# List of sensitive action codes to count in a session (values should be in upper case)
fortscale.session.failed.action.codes={ "CORP" : ["User Open Failed"] }

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.jsonmodel.class=fortscale.streaming.serialization.PrevalanceModelSerdeFactory
serializers.registry.amtsession.class=fortscale.streaming.serialization.AmtSessionSerdeFactory
serializers.registry.long.class=fortscale.streaming.serialization.LongSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory
serializers.registry.timebarrier.class=fortscale.streaming.serialization.UserTimeBarrierModelSerdeFactory

# Metric report every 60 seconds to a kafka topic called metrics
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
systems.kafka.producer.retry.backoff.ms=10000
systems.kafka.producer.acks=1
systems.kafka.producer.reconnect.backoff.ms=10000
systems.kafka.producer.queue.buffering.max.ms=2000
systems.kafka.producer.batch.num.messages=1000

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka

# Key-value storage
stores.sessionize-amt.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.sessionize-amt.changelog=kafka.sessionize-amt-changelog
stores.sessionize-amt.key.serde=string
stores.sessionize-amt.msg.serde=amtsession
# This property is set to the number of key/value pairs that should be kept in this in-memory buffer, per task instance. The number cannot be greater than stores.*.object.cache.size.
stores.sessionize-amt.write.batch.size=25
# This property determines the number of objects to keep in Samza's cache, per task instance. This same cache is also used for write buffering (see stores.*.write.batch.size). A value of 0 disables all caching and batching.
stores.sessionize-amt.object.cache.size=100
# The size of LevelDB's block cache in bytes, per container. Note that this is an off-heap memory allocation, so the container's total memory use is the maximum JVM heap size plus the size of this cache.
stores.sessionize-amt.container.cache.size.bytes=1000
# The amount of memory (in bytes) that LevelDB uses for buffering writes before they are written to disk.
stores.sessionize-amt.container.write.buffer.size.bytes=500
