# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.name=vpn-geolocation-session-update-task

# Task
task.class=fortscale.streaming.task.enrichment.VpnEnrichTask
task.inputs=kafka.fortscale-vpn-structured

# Fortscale specific task config parameters
fortscale.context=classpath*:META-INF/spring/streaming-VpnEnrichTask-context.xml
fortscale.output.topic=fortscale-vpn-geolocated-session-updated
fortscale.events.vpn.partition.field=impala.data.vpn.table.field.username
#geolocation fields:
fortscale.events.vpn.ip.field=impala.data.vpn.table.field.source_ip
fortscale.events.vpn.country.field=impala.data.vpn.table.field.country
fortscale.events.vpn.countryIsoCode.field=impala.data.vpn.table.field.countrycode
fortscale.events.vpn.region.field=impala.data.vpn.table.field.region
fortscale.events.vpn.city.field=impala.data.vpn.table.field.city
fortscale.events.vpn.isp.field=impala.data.vpn.table.field.isp
fortscale.events.vpn.usageType.field=impala.data.vpn.table.field.ipusage
fortscale.events.vpn.longtitude.field=longtitude
fortscale.events.vpn.latitude.field=latitude

#data buckets fields:
fortscale.events.vpn.totalbytes.field=impala.score.vpn.session.table.field.totalbytes
fortscale.events.vpn.readbytes.field=impala.score.vpn.session.table.field.readbytes
fortscale.events.vpn.duration.field=impala.score.vpn.session.table.field.duration
fortscale.events.vpn.databucket.field=impala.score.vpn.session.table.field.databucket
#session update fields:
fortscale.events.vpn.geoHoppingOpenSessionThresholdInHours = vpn.geohopping.open.session.threshold.in.hours
fortscale.events.vpn.geoHoppingCloseSessionThresholdInHours = vpn.geohopping.close.session.threshold.in.hours
fortscale.events.vpn.sessionid.field = sessionid
fortscale.events.vpn.runGeoHopping.field = run_geo_hopping_field
fortscale.events.vpn.addSessionData.field = vpn.sessionupdate.isAddSessionData
fortscale.events.vpn.username.field=impala.score.vpn.table.field.username

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory


# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.key.serde=string
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=async
systems.kafka.producer.retry.backoff.ms = 10000
systems.kafka.producer.acks = 1
systems.kafka.producer.reconnect.backoff.ms = 10000
systems.kafka.producer.queue.buffering.max.ms=2000
systems.kafka.producer.batch.num.messages=100
systems.kafka.producer.partitioner.class=fortscale.utils.kafka.partitions.StringHashPartitioner

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka
