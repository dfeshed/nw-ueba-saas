# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.shutdown.timeout.ms=300000
job.name=4769-prevalence-stats

# Task
task.class=fortscale.streaming.task.EventsPrevalenceModelStreamTask
task.inputs=kafka.fortscale-4769-event-filtered
# export the state to mongodb every 4 hours (4*60*60*1000=14,400,000ms)
task.window.ms=14400000
#task.opts=-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y

# Fortscale specific task config parameters
fortscale.context=classpath*:META-INF/spring/streaming-context.xml
fortscale.username.field=normalized_username
fortscale.source.type=4769
fortscale.entity.type=event
fortscale.timestamp.field=date_time_unix
fortscale.discriminator.fields=recordNumber
fortscale.store.name=4769-prevalence-stats
fortscale.models.names.order=4769user,4769DstComputer,4769SrcComputer

fortscale.model.4769user.context.fieldname=normalized_username
fortscale.model.4769user.fields.date_time_unix.model=fortscale.ml.model.prevalance.field.DailyTimeModel
fortscale.model.4769user.fields.nat_src_machine.model=fortscale.ml.model.prevalance.field.StringCaseInsensitiveValuesCalibrationModel
fortscale.model.4769user.fields.normalized_dst_machine.model=fortscale.ml.model.prevalance.field.StringCaseInsensitiveValuesCalibrationModel
fortscale.model.4769user.fields.failure_code.model=fortscale.ml.model.prevalance.field.StringCaseInsensitiveValuesCalibrationModel

fortscale.model.4769DstComputer.context.fieldname=normalized_dst_machine
fortscale.model.4769DstComputer.fields.normalized_username.model=fortscale.ml.model.prevalance.field.StringCaseInsensitiveValuesCalibrationModel

fortscale.model.4769SrcComputer.context.fieldname=nat_src_machine
fortscale.model.4769SrcComputer.fields.normalized_username.model=fortscale.ml.model.prevalance.field.StringCaseInsensitiveValuesCalibrationModel

fortscale.scorers=eventscorer

fortscale.score.eventscorer.output.field.name=eventscore
fortscale.score.eventscorer.scorer=max-scorer
fortscale.score.eventscorer.scorers=dateTimeScorer,hostnameScorer,destScorer,failureCodeScorer

fortscale.score.dateTimeScorer.output.field.name=date_timeScore
fortscale.score.dateTimeScorer.scorer=model-scorer
fortscale.score.dateTimeScorer.model.name=4769user
fortscale.score.dateTimeScorer.4769user.context.fieldname=normalized_username
fortscale.score.dateTimeScorer.4769user.fieldname=date_time_unix

fortscale.score.hostnameScorer.output.field.name=hostnameScore
fortscale.score.hostnameScorer.scorer=reducting-scorer
fortscale.score.hostnameScorer.main.scorer=hostnameMainScorer
fortscale.score.hostnameScorer.reducting.scorer=hostnameReductingScorer
fortscale.score.hostnameScorer.reducting.weight=0.5
fortscale.score.hostnameMainScorer.output.field.name=hostnameMainScore
fortscale.score.hostnameMainScorer.scorer=model-scorer
fortscale.score.hostnameMainScorer.model.name=4769user
fortscale.score.hostnameMainScorer.4769user.context.fieldname=normalized_username
fortscale.score.hostnameMainScorer.4769user.fieldname=nat_src_machine
fortscale.score.hostnameReductingScorer.output.field.name=hostnameReductingScore
fortscale.score.hostnameReductingScorer.scorer=model-scorer
fortscale.score.hostnameReductingScorer.model.name=4769SrcComputer
fortscale.score.hostnameReductingScorer.4769SrcComputer.context.fieldname=nat_src_machine
fortscale.score.hostnameReductingScorer.4769SrcComputer.fieldname=normalized_username


fortscale.score.destScorer.output.field.name=destScore
fortscale.score.destScorer.scorer=reducting-scorer
fortscale.score.destScorer.main.scorer=destMainScorer
fortscale.score.destScorer.reducting.scorer=destReductingScorer
fortscale.score.destScorer.reducting.weight=0.5
fortscale.score.destMainScorer.output.field.name=destMainScore
fortscale.score.destMainScorer.scorer=model-scorer
fortscale.score.destMainScorer.model.name=4769user
fortscale.score.destMainScorer.4769user.context.fieldname=normalized_username
fortscale.score.destMainScorer.4769user.fieldname=normalized_dst_machine
fortscale.score.destReductingScorer.output.field.name=destReductingScore
fortscale.score.destReductingScorer.scorer=model-scorer
fortscale.score.destReductingScorer.model.name=4769DstComputer
fortscale.score.destReductingScorer.4769DstComputer.context.fieldname=normalized_dst_machine
fortscale.score.destReductingScorer.4769DstComputer.fieldname=normalized_username


fortscale.score.failureCodeScorer.output.field.name=failure_codeScore
fortscale.score.failureCodeScorer.scorer=priority-scorer
fortscale.score.failureCodeScorer.scorers=failureCodeRegexScorer,failureCodeModelScorer
fortscale.score.failureCodeRegexScorer.output.field.name=failure_codeScore
fortscale.score.failureCodeRegexScorer.scorer=const-regex-scorer
fortscale.score.failureCodeRegexScorer.regex=0x12|0x22|0x6
fortscale.score.failureCodeRegexScorer.regex.fieldname=failure_code
fortscale.score.failureCodeRegexScorer.constant=100
fortscale.score.failureCodeModelScorer.output.field.name=failure_codeScore
fortscale.score.failureCodeModelScorer.scorer=model-scorer
fortscale.score.failureCodeModelScorer.model.name=4769user
fortscale.score.failureCodeModelScorer.4769user.context.fieldname=normalized_username
fortscale.score.failureCodeModelScorer.4769user.fieldname=failure_code

fortscale.output.topic=fortscale-4769-event-score
#fortscale.skip.score=false
#fortscale.skip.model=false

fortscale.filter.vpnpool.enabled=true
fortscale.filter.vpnpool.ip=10\.20\.16\.[0-9]+|10\.21\.[0-9]+\.[0-9]+|10\.24\.[0-9]+\.[0-9]+|10\.33\.84\.[0-9]+|10\.35\.[0-9]+\.[0-9]+|10\.56\.[0-9]+\.[0-9]+|10\.59\.[0-9]+\.[0-9]+|10\.61\.[0-9]+\.[0-9]+|10\.63\.[0-9]+\.[0-9]+|10\.65\.[0-9]+\.[0-9]+|10\.66\.[0-9]+\.[0-9]+|10\.68\.[0-9]+\.[0-9]+|10\.70\.[0-9]+\.[0-9]+|10\.75\.[0-9]+\.[0-9]+|10\.79\.[0-9]+\.[0-9]+|10\.82\.[0-9]+\.[0-9]+|10\.85\.[0-9]+\.[0-9]+|10\.86\.[0-9]+\.[0-9]+|10\.89\.[0-9]+\.[0-9]+|172\.30\.[0-9]+\.[0-9]+|192\.0\.2\.[0-9]+


# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.jsonmodel.class=fortscale.streaming.serialization.PrevalanceModelSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory


# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
systems.kafka.producer.retry.backoff.ms = 10000
systems.kafka.producer.acks = 1
systems.kafka.producer.reconnect.backoff.ms = 10000
systems.kafka.producer.queue.buffering.max.ms=2000
systems.kafka.producer.batch.num.messages=1000

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka


# Key-value storage
stores.4769-prevalence-stats.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.4769-prevalence-stats.changelog=kafka.4769-prevalence-stats-changelog
stores.4769-prevalence-stats.key.serde=string
stores.4769-prevalence-stats.msg.serde=jsonmodel

# This property is set to the number of key/value pairs that should be kept in this in-memory buffer, per task instance. The number cannot be greater than stores.*.object.cache.size.
stores.4769-prevalence-stats.write.batch.size=50
# This property determines the number of objects to keep in Samza's cache, per task instance. This same cache is also used for write buffering (see stores.*.write.batch.size). A value of 0 disables all caching and batching.
stores.4769-prevalence-stats.object.cache.size=500
# The size of LevelDB's block cache in bytes, per container. Note that this is an off-heap memory allocation, so the container's total memory use is the maximum JVM heap size plus the size of this cache.
stores.4769-prevalence-stats.container.cache.size.bytes=500000
# The amount of memory (in bytes) that LevelDB uses for buffering writes before they are written to disk,
stores.4769-prevalence-stats.container.write.buffer.size.bytes=1000
	
