# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.name=field-tagging-by-list

# Task
task.class=fortscale.streaming.task.enrichment.FieldTaggingByListTask
task.inputs=kafka.fortscale-amt-structured


# Fortscale specific task config parameters
fortscale.context=classpath*:META-INF/spring/streaming-TaggingTask-context.xml

# map cache logic name into topic and store name
fortscale.amt.service.cache.store=sensetiveMachine-as-VIP-cache


# map event input topic into output topics and field names to resolve in each type of event
fortscale.events.amt.input.topic=fortscale-amt-structured
fortscale.events.amt.output.topic=fortscale-amt-fields-tagged
fortscale.events.amt.partition.field=impala.score.amt.table.field.username
fortscale.events.amt.file.path=user.list.service_sensitive_machine.path
fortscale.events.amt.tag.field.name=impala.score.amt.table.field.is_sensitive_machine
fortscale.events.amt.tagging.based.field.name=impala.score.amt.table.field.yid


# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory


# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot


# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.key.serde=string
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
systems.kafka.producer.retry.backoff.ms = 10000
systems.kafka.producer.acks = 1
systems.kafka.producer.reconnect.backoff.ms = 10000
systems.kafka.producer.partitioner.class=fortscale.utils.kafka.partitions.StringHashPartitioner
systems.kafka.producer.queue.buffering.max.ms=2000
systems.kafka.producer.batch.num.messages=1000


# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka



# Key-value storage for sensitive-machine-service-cache
stores.sensetiveMachine-as-VIP-cache.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.sensetiveMachine-as-VIP-cache.changelog=kafka.sensetiveMachine-as-VIP-cache-changelog
stores.sensetiveMachine-as-VIP-cache.key.serde=string
stores.sensetiveMachine-as-VIP-cache.msg.serde=string
stores.sensetiveMachine-as-VIP-cache.write.batch.size=25
stores.sensetiveMachine-as-VIP-cache.object.cache.size=100000
stores.sensetiveMachine-as-VIP-cache.container.cache.size.bytes=20971520
stores.sensetiveMachine-as-VIP-cache.container.write.buffer.size.bytes=102400
