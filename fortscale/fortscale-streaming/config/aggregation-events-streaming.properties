# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.shutdown.timeout.ms=300000
job.name=aggregation-events-streaming

# Task
task.class=fortscale.streaming.task.AggregationEventsStreamTask

# Needs to be changed to kafka.fortscale-ssh-model
task.inputs=kafka.fortscale-all-events-score-after-write
#  every 1 minutes ( 60 * 1000 = 60,000 ms)
task.window.ms=60000

# Fortscale specific task config parameters
fortscale.context=classpath*:META-INF/spring/streaming-aggr-context.xml
fortscale.timestamp.field=${impala.table.fields.epochtime}
fortscale.data.source.field=${impala.table.fields.data.source}

#data source configuration:
fortscale.ssh.input.topic=fortscale-ssh-event-score
fortscale.kerberos_logins.input.topic=fortscale-4769-event-score
fortscale.amt.input.topic=fortscale-amt-event-score
fortscale.vpn.input.topic=fortscale-vpn-event-score
fortscale.vpn_session.input.topic=fortscale-vpnsession-event-score

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Metric report every 60 seconds to a kafka topic called metrics
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
systems.kafka.producer.retry.backoff.ms=10000
systems.kafka.producer.acks=1
systems.kafka.producer.reconnect.backoff.ms=10000
systems.kafka.producer.queue.buffering.max.ms=2000
systems.kafka.producer.batch.num.messages=1000

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka


