# Job
job.factory.class=fortscale.streaming.GracefulShutdownLocalJobFactory
job.name=ip-resolving

# Task
task.class=fortscale.streaming.task.IpResolvingStreamTask
task.inputs=kafka.dns-resolver-cache,kafka.dns-resolver-blacklist,kafka.dhcp-resolver-cache,kafka.login-resolver-cache

# Fortscale specific task config parameters
fortscale.context=classpath*:META-INF/spring/streaming-TaggingTask-context.xml

# map cache logic name into topic and store name
fortscale.dns-cache.topic=dns-resolver-cache
fortscale.dns-cache.store=dns-resolver-cache
fortscale.dns-blacklist.topic=dns-resolver-blacklist
fortscale.dns-blacklist.store=dns-resolver-blacklist
fortscale.dhcp-cache.topic=dhcp-resolver-cache
fortscale.dhcp-cache.store=dhcp-resolver-cache
fortscale.login-cache.topic=login-resolver-cache
fortscale.login-cache.store=login-resolver-cache

# map event input topic into output topics and field names to resolve in each type of event - DUMMY CONFIGS, WILL BE REPLACED NEXT PULL REQUEST
fortscale.events.secevt.input.topic=
fortscale.events.secevt.output.topic=
fortscale.events.secevt.ip.field=
fortscale.events.secevt.host.field=
fortscale.events.secevt.timestamp.field=
fortscale.events.secevt.restrictToADName
fortscale.events.secevt.shortName
fortscale.events.secevt.isRemoveLastDot



# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.long.class=fortscale.streaming.serialization.LongSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory

# Metric report every 60 seconds to a kafka topic called metrics and as a monitor report
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.metrics
metrics.reporter.monitor.class=fortscale.streaming.metrics.MongoMetricsSnapshotReporterFactory
systems.kafka.streams.metrics.samza.msg.serde=metrics
metrics.reporters=snapshot,monitor


# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.samza.offset.default=oldest
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
systems.kafka.producer.retry.backoff.ms = 10000
systems.kafka.producer.acks = 1
systems.kafka.producer.reconnect.backoff.ms = 10000

# Normally, we'd set this much higher, but we want things to look snappy in the demo.
systems.kafka.producer.batch.num.messages=1

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka

# topic priorities for cache updates should be higher than those for the events topics
systems.kafka.streams.dns-resolver-cache.samza.bootstrap=true
systems.kafka.streams.dns-resolver-blacklist.samza.bootstrap=true
systems.kafka.streams.dhcp-resolver-cache.samza.bootstrap=true
systems.kafka.streams.login-resolver-cache.samza.bootstrap=true

# Key-value storage for dns resolver cache
stores.dns-resolver-cache.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.dns-resolver-cache.key.serde=string
stores.dns-resolver-cache.msg.serde=json
stores.dns-resolver-cache.write.batch.size=25
stores.dns-resolver-cache.object.cache.size=100000
stores.dns-resolver-cache.container.cache.size.bytes=1073741824
stores.dns-resolver-cache.container.write.buffer.size.bytes=102400

# Key-value storage for dns-resolver-blacklist
stores.dns-resolver-blacklist.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.dns-resolver-blacklist.key.serde=string
stores.dns-resolver-blacklist.msg.serde=json
stores.dns-resolver-blacklist.write.batch.size=25
stores.dns-resolver-blacklist.object.cache.size=100000
stores.dns-resolver-blacklist.container.cache.size.bytes=1073741824
stores.dns-resolver-blacklist.container.write.buffer.size.bytes=102400

# Key-value storage for dhcp-resolver-cache
stores.dhcp-resolver-cache.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.dhcp-resolver-cache.key.serde=string
stores.dhcp-resolver-cache.msg.serde=json
stores.dhcp-resolver-cache.write.batch.size=25
stores.dhcp-resolver-cache.object.cache.size=100000
stores.dhcp-resolver-cache.container.cache.size.bytes=1073741824
stores.dhcp-resolver-cache.container.write.buffer.size.bytes=102400


# Key-value storage for logic-resolver-cache
stores.login-resolver-cache.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.login-resolver-cache.key.serde=string
stores.login-resolver-cache.msg.serde=json
stores.login-resolver-cache.write.batch.size=25
stores.login-resolver-cache.object.cache.size=100000
stores.login-resolver-cache.container.cache.size.bytes=1073741824
stores.login-resolver-cache.container.write.buffer.size.bytes=102400


