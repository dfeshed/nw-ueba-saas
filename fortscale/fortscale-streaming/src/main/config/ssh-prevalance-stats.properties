# Job
job.factory.class=org.apache.samza.job.local.LocalJobFactory
job.name=ssh-prevalence-stats

# Task
task.class=fortscale.streaming.task.EventsPrevalenceModelStreamTask
task.inputs=kafka.fortscale-ssh-structured
# export the state to mongodb every 30 minutes (30*60*1000=1800000ms)
task.window.ms=1800000
#task.opts=-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y

# Fortscale specific task config parameters
fortscale.username.field=normalized_username
fortscale.timestamp.field=date_time_unix
fortscale.store.name=ssh-prevalence-stats
fortscale.model.name=ssh
fortscale.fields.date_time_unix.model=fortscale.streaming.model.field.DailyTimeModel
fortscale.fields.date_time_unix.output=date_timeScore
fortscale.fields.normalized_dst_machine.model=fortscale.streaming.model.field.StringCaseInsensitiveValuesCalibrationModel
fortscale.fields.normalized_dst_machine.output=normalized_dst_machine_score
fortscale.fields.normalized_src_machine.model=fortscale.streaming.model.field.StringCaseInsensitiveValuesCalibrationModel
fortscale.fields.normalized_src_machine.output=normalized_src_machine_score
fortscale.fields.auth_method.model=fortscale.streaming.model.field.StringCaseInsensitiveValuesCalibrationModel
fortscale.fields.auth_method.output=auth_method_score
fortscale.event.score.field=eventscore
fortscale.output.topic=fortscale-ssh-event-score
#fortscale.skip.score=false
#fortscale.skip.model=false

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.jsonmodel.class=fortscale.streaming.serialization.PrevalanceModelSerdeFactory


# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
# Normally, we'd set this much higher, but we want things to look snappy in the demo.
systems.kafka.producer.batch.num.messages=1

# Declare that we want our job's checkpoints to be enabled and written to Kafka
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.replication.factor=1
task.checkpoint.system=kafka

# Key-value storage
stores.ssh-prevalence-stats.factory=org.apache.samza.storage.kv.KeyValueStorageEngineFactory
stores.ssh-prevalence-stats.changelog=kafka.ssh-prevalence-stats-changelog
stores.ssh-prevalence-stats.key.serde=string
stores.ssh-prevalence-stats.msg.serde=jsonmodel
# Normally, we'd set this much higher, but we want things to look snappy in the demo.
stores.ssh-prevalence-stats.write.batch.size=0
stores.ssh-prevalence-stats.object.cache.size=0