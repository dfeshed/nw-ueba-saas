# Job
job.factory.class=org.apache.samza.job.local.LocalJobFactory
job.name=vpn-prevalence-stats

# Task
task.class=fortscale.streaming.task.HDFSWriterStreamTask
task.inputs=kafka.fortscale-vpn-event-score
# flush the hdfs writers every 30 minutes (30*60*1000=1800000ms)
task.window.ms=1800000
#task.opts=-agentlib:jdwp=transport=dt_socket,address=localhost:9009,server=y,suspend=y

# Fortscale specific task config parameters
fortscale.timestamp.field=date_time_unix
fortscale.fields=date_time,date_time_unix,date_timeScore,username,status,source_ip,hostname,hostnameScore,local_ip,country,countryScore,countrycode,region,city,isp,ipusage,eventscore
fortscale.separator=,
fortscale.hdfs.root=/user/cloudera/processeddata/vpn
fortscale.table.name=vpndatares
fortscale.file.name=vpnETL.csv
fortscale.partition.strategy=fortscale.utils.hdfs.partition.MonthlyPartitionStrategy
fortscale.split.strategy=fortscale.utils.hdfs.split.DailyFileSplitStrategy


# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory
serializers.registry.integer.class=org.apache.samza.serializers.IntegerSerdeFactory
serializers.registry.jsonmodel.class=fortscale.streaming.serialization.PrevalanceModelSerdeFactory


# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=string
systems.kafka.consumer.zookeeper.connect=localhost:2181
systems.kafka.consumer.auto.offset.reset=largest
systems.kafka.producer.metadata.broker.list=localhost:9092
systems.kafka.producer.producer.type=sync
# Normally, we'd set this much higher, but we want things to look snappy in the demo.
systems.kafka.producer.batch.num.messages=1