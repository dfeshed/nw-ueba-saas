{
  "data-source-scorers": [
    {
      "data-source": "oracle",
      "scorers": [
        {
          "type": "pareto-scorer",
          "name": "oracle-event-scorer",
          "highest-score-weight": 0.8,
          "scorers": [
            {
              "type": "time-model-scorer",
              "name": "date_time_unix.normalized_username.oracle.scorer",
              "model": {
                "name": "date_time_unix.normalized_username.oracle"
              },
              "number-of-samples-to-influence-enough": 30,
              "use-certainty-to-calculate-score": true
            },
            {
              "type": "category-rarity-model-scorer",
              "name": "action_type.normalized_username.oracle.scorer",
              "model": {
                "name": "action_type.normalized_username.oracle"
              },
              "max-rare-count": 5,
              "max-num-of-rare-features": 15,
              "number-of-samples-to-influence-enough": 30,
              "use-certainty-to-calculate-score": true
            },
            {
              "type": "category-rarity-model-scorer",
              "name": "return_code.normalized_username.oracle.scorer",
              "model": {
                "name": "return_code.normalized_username.oracle"
              },
              "max-rare-count": 5,
              "max-num-of-rare-features": 15,
              "number-of-samples-to-influence-enough": 30,
              "use-certainty-to-calculate-score": true
            },
            {
              "type": "category-rarity-model-scorer",
              "name": "db_object.normalized_username.oracle.scorer",
              "model": {
                "name": "db_object.normalized_username.oracle"
              },
              "max-rare-count": 5,
              "max-num-of-rare-features": 15,
              "number-of-samples-to-influence-enough": 30,
              "use-certainty-to-calculate-score": true
            },
            {
              "type": "reduction-scorer",
              "name": "normalizedSrcMachineScorer",
              "main-scorer": {
                "type": "category-rarity-model-scorer",
                "name": "normalized_src_machine.normalized_username.oracle.scorer",
                "model": {
                  "name": "normalized_src_machine.normalized_username.oracle"
                },
                "max-rare-count": 5,
                "max-num-of-rare-features": 15
              },
              "reduction-scorer": {
                "type": "category-rarity-model-scorer",
                "name": "normalized_username.normalized_src_machine.oracle.scorer",
                "model": {
                  "name": "normalized_username.normalized_src_machine.oracle"
                },
                "max-rare-count": 5,
                "max-num-of-rare-features": 15
              },
              "reduction-weight": 0.5
            },
            {
              "type": "reduction-scorer",
              "name": "normalizedDstMachineScorer",
              "main-scorer": {
                "type": "category-rarity-model-scorer",
                "name": "normalized_dst_machine.normalized_username.oracle.scorer",
                "model": {
                  "name": "normalized_dst_machine.normalized_username.oracle"
                },
                "max-rare-count": 5,
                "max-num-of-rare-features": 15
              },
              "reduction-scorer": {
                "type": "category-rarity-model-scorer",
                "name": "normalized_username.normalized_dst_machine.oracle.scorer",
                "model": {
                  "name": "normalized_username.normalized_dst_machine.oracle"
                },
                "max-rare-count": 5,
                "max-num-of-rare-features": 15
              },
              "reduction-weight": 0.5
            },
            {
              "type": "category-rarity-model-scorer",
              "name": "db_username.normalized_username.oracle.scorer",
              "model": {
                "name": "db_username.normalized_username.oracle"
              },
              "max-rare-count": 5,
              "max-num-of-rare-features": 15,
              "number-of-samples-to-influence-enough": 30,
              "use-certainty-to-calculate-score": true
            }
          ]
        }
      ]
    }
  ]
}
