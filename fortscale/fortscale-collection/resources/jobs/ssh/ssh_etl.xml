<?xml version='1.0' encoding='utf-8'?>
<job-scheduling-data
	xmlns="http://www.quartz-scheduler.org/xml/JobSchedulingData"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://www.quartz-scheduler.org/xml/JobSchedulingData http://www.quartz-scheduler.org/xml/job_scheduling_data_2_0.xsd"
	version="2.0">

	<schedule>
		<job>
			<name>ETL</name>
			<group>SSH</group>
			<description>process ssh events received from splunk into files</description>
			<job-class>fortscale.collection.jobs.SSHEventProcessJob</job-class>
			<durability>true</durability>
			<recover>true</recover>
			
			<job-data-map>
				<entry>
					<key>filesFilter</key>
					<value>SSH_\d+.csv$</value>
				</entry>
				<entry>
					<key>outputFields</key>
					<value>${impala.data.ssh.table.fields}</value>
				</entry>
				<entry>
					<key>timestampField</key>
					<value>${impala.data.table.fields.epochtime}</value>
				</entry>
				<entry>
					<key>outputSeparator</key>
					<value>${impala.data.ssh.table.delimiter}</value>
				</entry>
				<entry>
					<key>morphlineFile</key>
					<value>file:resources/conf-files/readSSH_centos.conf</value>
				</entry>
				<entry>
					<key>hadoopPath</key>
					<value>${hdfs.user.data.ssh.path}</value>
				</entry>
				<entry>
					<key>hadoopFilename</key>
					<value>sshData.csv</value>
				</entry>
				<entry>
					<key>impalaTableName</key>
					<value>sshdata</value>
				</entry>
				<entry>
					<key>streamingTopic</key>
					<value>${kafka.ssh.struct.topic}</value>
				</entry>
			</job-data-map>
		</job>
		
	</schedule>
	
</job-scheduling-data>